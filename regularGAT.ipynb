{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07bc86a-4f2f-4362-b351-a5f547ff8c89",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "Before using those packages in gpu, be sure that all torch-related package is in correct cuda version.\n",
    "- `nvidia-smi CUDA Version (12.5)`: This version indicates the maximum CUDA version supported by the installed NVIDIA driver. It reflects the driver’s capability to run CUDA applications that are built with any CUDA version up to 12.5.\n",
    "- `nvcc --version CUDA Version (12.1)`: This version refers to the version of the CUDA toolkit installed on your system. The CUDA toolkit includes the CUDA compiler (nvcc), libraries, and other tools for developing CUDA applications.\n",
    "- python == 3.10\n",
    "- torch == 2.1.0+cu121 \n",
    "- pyg_lib == 0.3.1+pt21cu121\n",
    "- torch_cluster == 1.6.3+pt21cu121\n",
    "- torch_scatter == 2.1.2+pt21cu121\n",
    "- torch_sparse == 0.6.18+pt21cu121\n",
    "- torch_spline_conv == 1.2.2+pt21cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b15d48-c233-451b-ab1e-3d54dd497476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "598f97f5-2c57-44df-b854-6ab70671df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_dense_adj, dense_to_sparse, degree, add_self_loops, remove_self_loops, softmax, is_torch_sparse_tensor\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.typing import Adj, OptTensor, PairTensor, OptPairTensor, Size, NoneType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02283a12-0e1e-4aca-9c33-c8358ada67a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_sparse import SparseTensor, set_diag\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37c07d3-b81c-47c2-aa05-190f7afbdced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_add\n",
    "from typing import Optional, Tuple, Union\n",
    "from livelossplot import PlotLosses\n",
    "from pathlib import Path\n",
    "from utility import MyGATConv, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe4f54c-bfc0-415b-8eb4-669c86a20a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import gymnasium\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune import Trainable\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "# from ray.rllib.algorithms.ppo import PPO, PPOConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43af4082-01c7-45d8-8f3c-f1b6919e7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "# ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121dcb7-7ae0-4837-a9da-c042f15e41ba",
   "metadata": {},
   "source": [
    "## rGAT Model:\n",
    "\n",
    "****\n",
    "\n",
    "- `radius_threshold`: 500~5000\n",
    "- `interval`: the interval of each radius, setted as 50\n",
    "- `brain_data`\n",
    "- `select_family`\n",
    "- **Other hyperparameters**: `my_hidden_channels`, `my_heads`,`my_dropout`,`my_lr`,`num_epochs`\n",
    "- The graph attentional operator from the [\"Graph Attention Networks\"](https://arxiv.org/abs/1710.10903)\n",
    "\n",
    "\n",
    "$$\n",
    "        \\mathbf{x}^{\\prime}_i = \\alpha_{i,i}\\mathbf{\\Theta}_{s}\\mathbf{x}_{i} +\n",
    "        \\sum_{j \\in \\mathcal{N}(i)}\n",
    "        \\alpha_{i,j}\\mathbf{\\Theta}_{t}\\mathbf{x}_{j},\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "        \\alpha_{i,j} =\n",
    "        \\frac{\n",
    "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\n",
    "        \\mathbf{a}^{\\top}_{s} \\mathbf{\\Theta}_{s}\\mathbf{x}_i\n",
    "        + \\mathbf{a}^{\\top}_{t} \\mathbf{\\Theta}_{t}\\mathbf{x}_j\n",
    "        \\right)\\right)}\n",
    "        {\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
    "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\n",
    "        \\mathbf{a}^{\\top}_{s} \\mathbf{\\Theta}_{s}\\mathbf{x}_i\n",
    "        + \\mathbf{a}^{\\top}_{t}\\mathbf{\\Theta}_{t}\\mathbf{x}_k\n",
    "        \\right)\\right)}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "        \\alpha_{i,j} =\n",
    "        \\frac{\n",
    "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\n",
    "        \\mathbf{a}^{\\top}_{s} \\mathbf{\\Theta}_{s}\\mathbf{x}_i\n",
    "        + \\mathbf{a}^{\\top}_{t} \\mathbf{\\Theta}_{t}\\mathbf{x}_j\n",
    "        + \\mathbf{a}^{\\top}_{e} \\mathbf{\\Theta}_{e} \\mathbf{e}_{i,j}\n",
    "        \\right)\\right)}\n",
    "        {\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
    "        \\exp\\left(\\mathrm{LeakyReLU}\\left(\n",
    "        \\mathbf{a}^{\\top}_{s} \\mathbf{\\Theta}_{s}\\mathbf{x}_i\n",
    "        + \\mathbf{a}^{\\top}_{t} \\mathbf{\\Theta}_{t}\\mathbf{x}_k\n",
    "        + \\mathbf{a}^{\\top}_{e} \\mathbf{\\Theta}_{e} \\mathbf{e}_{i,k}\n",
    "        \\right)\\right)}.\n",
    "$$\n",
    "\n",
    "## Shapes:\n",
    "\n",
    "- **input:**\n",
    "  node features:\n",
    "  $(|\\mathcal{V}|, F_{in})$ or\n",
    "  $((|\\mathcal{V_s}|, F_{s}), (|\\mathcal{V_t}|, F_{t}))$\n",
    "  if bipartite,\n",
    "  edge indices $(2, |\\mathcal{E}|)$,\n",
    "  edge features $(|\\mathcal{E}|, D)$ *(optional)*\n",
    "- **output:** node features $(|\\mathcal{V}|, H * F_{out})$ or\n",
    "  $((|\\mathcal{V}_t|, H * F_{out})$ if bipartite.\n",
    "  If `return_attention_weights=True`, then\n",
    "  $((|\\mathcal{V}|, H * F_{out}),\n",
    "  ((2, |\\mathcal{E}|), (|\\mathcal{E}|, H)))$\n",
    "  or $((|\\mathcal{V_t}|, H * F_{out}), ((2, |\\mathcal{E}|),\n",
    "  (|\\mathcal{E}|, H)))$ if bipartite\n",
    "\n",
    "\n",
    "\n",
    "## Before Start... ##\n",
    "\n",
    "****\n",
    "\n",
    "- Check if all elements are stored in `cuda`\n",
    "- Hyperparameter:\n",
    "    - `my_hidden_channels`: 64\n",
    "    - `my_heads`: 1\n",
    "    - `dropout`: 0.6\n",
    "    - `mu_lr`: learning rate set as 0.01\n",
    "    - `epoch`: set epoch as 50, deter model from overfitting\n",
    "\n",
    "### Set Head:\n",
    "\n",
    "[Reference](https://petar-v.com/GAT/)\n",
    "\n",
    "To stabilise the learning process of self-attention, we have found multi-head attention to be very beneficial [(as was the case in Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762). Namely, the operations of the layer are independently replicated K times (each replica with different parameters), and outputs are featurewise aggregated (typically by concatenating or adding).\n",
    "$$\n",
    "\\vec{h^\\prime_i} = \\Vert^k_{k=1} \\sigma \\lgroup \\sum_{j\\in N_i}\\alpha^k_{i,j} \\mathrm{W}^k \\vec{h_j}\\rgroup\n",
    "$$\n",
    "where $\\alpha_{i,j}$ are the attention coefficients derived by the $k$-th replica, and $W_k$ the weight matrix specifying the linear transformation of the $k$-th replica. With the setup of the preceding sections, this fully specifies a **Graph Attention Network (GAT)** layer!\n",
    "\n",
    "A GAT layer with multi-head attention. Every neighbour $i$ of node 1 sends its own vector of attentional coefficients,$\\vec{\\alpha_{1i}}$ one per each attention head $\\alpha_{1i}^k$. These are used to compute K separate linear combinations of neighbours’ features $\\vec{h_i}$, which are then aggregated (typically by concatenation or averaging) to obtain the next-level features of node 1,$\\vec{h^\\prime_1}$.\n",
    "\n",
    "### Set Dropout:\n",
    "Furthermore, we have found that applying dropout [(Srivastava et al., 2014)](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf) to the attentional coefficients $\\alpha_{i,j}$ was a highly beneficial regulariser, especially for small training datasets. This effectively exposes nodes to stochastically sampled neighbourhoods during training, in a manner reminiscent of the (concurrently published) FastGCN method [(Chen et al., 2018)](https://arxiv.org/abs/1801.10247).\n",
    "\n",
    "Dropout is a technique that addresses both these issues. It prevents overfitting and provides a way of approximately combining exponentially many different neural network\n",
    "architectures efficiently. The term “dropout” refers to dropping out units (hidden and visible) in a neural network. By dropping a unit out, we mean temporarily removing it from the network, along with all its incoming and outgoing connections, as shown in Figure 1.\n",
    "\n",
    "The choice of which units to drop is random. In the simplest case, each unit is retained with a fixed probability $p$ independent of other units, where $p$ can be chosen using a validation set or can simply be set at 0.5, which seems to be close to optimal for a wide range of networks and tasks. For the input units, however, the optimal probability of retention is usually closer to 1 than to 0.5\n",
    "\n",
    "****\n",
    "\n",
    "## K-Fold\n",
    "\n",
    "The training data used in the model is split, into k number of smaller sets, to be used to validate the model. The model is then trained on k-1 folds of training set. The remaining fold is then used as a validation set to evaluate the model.\n",
    "\n",
    "As we will be trying to classify different species of iris flowers we will need to import a classifier model, for this exercise we will be using a DecisionTreeClassifier. We will also need to import CV modules from sklearn.\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score \n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "k_folds = KFold(n_splits = 5)\n",
    "scores = cross_val_score(clf, X, y, cv = k_folds)\n",
    "\n",
    "```\n",
    "\n",
    "Assigning X and y:\n",
    "- X (features): Typically, the x (node features) would be your input X. So in your case, X = data.x, which represents the feature matrix for the nodes.\n",
    "- y (targets): The y here could refer to either:\n",
    "- y (downstream genes): These could be your target variables if you are predicting gene expression or similar outcomes.\n",
    "- labels (embedded cluster names): These could be your target labels if you are performing a clustering or classification task.\n",
    "\n",
    "Which one to use as y depends on the specific task you are performing:\n",
    "- If you are predicting gene expression (a multi-output task), use data.y.\n",
    "- If you are performing node classification (predicting cluster labels), use data.labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c88976-da28-47bb-b67b-c35996f19095",
   "metadata": {},
   "source": [
    "### No finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb30f81-6b98-45bb-a814-570a6104cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regular GAT model to get initial attention weights\n",
    "class RegularGAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels_x, in_channels_t, out_channels, hidden_channels, heads, dropout):\n",
    "        super(RegularGAT, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.embedding = torch.nn.Embedding(in_channels_t, hidden_channels).to(self.device)  # Embedding layer for T: cell_types\n",
    "        self.gat1 = MyGATConv(in_channels_x, hidden_channels, heads=heads, dropout=0, add_self_loops=False)  # default dropout=0\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_channels + hidden_channels, hidden_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LayerNorm(hidden_channels), \n",
    "            torch.nn.Linear(hidden_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LayerNorm(out_channels)\n",
    "        ).to(self.device)\n",
    "        self.bn = torch.nn.BatchNorm1d(out_channels * heads).to(self.device)\n",
    "        self.dropout = dropout\n",
    "        # self.gat2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=0)\n",
    "        self.initial_attention_weights_abs = None\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, t = data.x, data.edge_index, data.labels\n",
    "        t_indices = torch.argmax(t, dim=1).to(self.device)\n",
    "        t_emb = self.embedding(t_indices).to(self.device)  # Get the embedding for T\n",
    "        x, (edge_index, (attention_scores, attention_weights)) = self.gat1(x, edge_index, return_attention_weights=True)\n",
    "        print(f'after GAT relu x: {x}')\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = torch.cat([x, t_emb], dim=1)\n",
    "        \n",
    "        x = self.mlp(x)  # Apply MLP to combined features with LayerNorm\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        print(f'after mlp and dropout x: {x}')\n",
    "        \n",
    "        # x, attention_weights = self.gat2(x, edge_index, return_attention_weights=True)\n",
    "        \n",
    "        if self.initial_attention_weights_abs is None:\n",
    "            self.initial_attention_weights_abs = torch.abs(attention_weights[1]).detach()\n",
    "        return x.to(self.device), attention_scores.to(self.device), attention_weights.to(self.device)  # Return the attention coefficients as well\n",
    "   \n",
    "    def _initialize_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(module.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "198ba70d-8341-4c41-b754-a1a8e14372ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training process\n",
    "def train(data, device):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out, attention_scores, attention_weights = model(data)\n",
    "    loss = F.mse_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    # penalty = model.compute_attention_penalty(attention_weights)\n",
    "    # total_loss = loss + penalty\n",
    "    total_loss = loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    return total_loss.item(), attention_weights.cpu().detach().numpy(), attention_scores.cpu().detach().numpy()\n",
    "\n",
    "def validate(data, device):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        out, attention_scores, attention_weights = model(data)\n",
    "        loss = F.mse_loss(out[data.val_mask], data.y[data.val_mask])\n",
    "        # penalty = model.compute_attention_penalty(attention_weights)\n",
    "        # total_loss = loss + penalty\n",
    "        total_loss = loss\n",
    "    return total_loss.item(), attention_weights.cpu().detach().numpy(), attention_scores.cpu().detach().numpy()\n",
    "\n",
    "def test(data, device):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        out, _, _ = model(data)\n",
    "        test_loss = F.mse_loss(out[data.test_mask], data.y[data.test_mask])\n",
    "    return test_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "838949dd-24bf-451a-9ad6-64d867d64c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c4bf59-c57e-4ffb-a812-72cd23753246",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './rGAT'\n",
    "radius_threshold = 500  # 500, 200, 1000\n",
    "brain_data = 'right'\n",
    "select_family = 'Neurotrophins'\n",
    "\n",
    "my_hidden_channels = 128\n",
    "my_heads = 1\n",
    "my_dropout = 0.3\n",
    "my_lr = 0.001\n",
    "num_epochs = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a1710-4f87-4a33-b218-36e5eedf926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(f'{file_path}/processed_for_CV/Radius_1000_Neurotrophins_ligand_target_left.data')\n",
    "\n",
    "radius_threshold = 1000\n",
    "model = RegularGAT(\n",
    "    in_channels_x=data.x.shape[1], \n",
    "    in_channels_t=data.labels.shape[1], \n",
    "    out_channels=data.y.shape[1], \n",
    "    hidden_channels=my_hidden_channels, \n",
    "    heads=my_heads, \n",
    "    dropout=my_dropout\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=my_lr)\n",
    "\n",
    "basename = f'RegularGAT_hidden_{my_hidden_channels}_head_{my_heads}_drop_{my_dropout}_lr_{my_lr}_right_Radius_200'\n",
    "\n",
    "#####\n",
    "\n",
    "checkpoint = f'{file_path}/rGAT_cosmx_yes_CV/models/checkpoints/{basename}'  # model weights\n",
    "history = f'{file_path}/rGAT_cosmx_yes_CV/history/{basename}'  # attention score and weights\n",
    "logfile = f'{file_path}/rGAT_cosmx_yes_CV/logs/log_{basename}.txt'  # training history\n",
    "\n",
    "if not os.path.exists(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "if not os.path.exists(history):\n",
    "    os.makedirs(history)\n",
    "\n",
    "\n",
    "log_dir = os.path.dirname(logfile)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "if not os.path.exists(logfile):\n",
    "    Path(logfile).touch()\n",
    "    \n",
    "log_file = open(logfile, 'w')\n",
    "\n",
    "#####\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "attention_weights_history = [] ## after normalized\n",
    "attention_scores_history = []\n",
    "\n",
    "#####\n",
    "\n",
    "logs = {}\n",
    "\n",
    "groups = {'total_loss': ['train_total_loss', 'val_total_loss'],\n",
    "          'sparsity': ['train_sparsity']}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_total_loss, train_attention_weights, train_attention_scores = train(data, device)\n",
    "    val_total_loss, val_attention_weights, val_attention_scores = validate(data, device)\n",
    "    logs['train_total_loss'] = train_total_loss\n",
    "    logs['val_total_loss'] = val_total_loss\n",
    "    log_file.write(f'{logs}\\n')\n",
    "    \n",
    "    attention_weights_history.append(train_attention_weights)\n",
    "    attention_scores_history.append(train_attention_scores)\n",
    "    \n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        torch.save(model.state_dict(), f'{checkpoint}/model_epoch_{epoch+1}.pth')\n",
    "        \n",
    "log_file.close()\n",
    "\n",
    "np.save(history + '/attention_weights.npy', np.array(attention_weights_history))\n",
    "test_loss = test(data, device)\n",
    "print(f'Radius {radius_threshold}: Test MSE: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a805fb-a569-4f42-8efa-613ef2762afc",
   "metadata": {},
   "source": [
    "### Supplementary: How NCEM Get R Square?\n",
    "\n",
    "**Step1:**\n",
    "- $y_{\\text{true}}$ is the vector of true values.\n",
    "- $y_{\\text{pred}}$ is the vector of predicted values.\n",
    "\n",
    "**Step2: The R-squared value,  $R^2$ , is calculated as:**\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} \\left( y_{\\text{true}, i} - y_{\\text{pred}, i} \\right)^2}{\\sum_{i=1}^{n} \\left( y_{\\text{true}, i} - \\bar{y}_{\\text{true}} \\right)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bar{y}_{\\text{true}} = \\frac{1}{n} \\sum_{i=1}^{n} y_{\\text{true}, i}\n",
    "$$\n",
    "\n",
    "**Explanation**\n",
    "\n",
    "- Residual Sum of Squares (RSS):  $\\sum_{i=1}^{n} \\left( y_{\\text{true}, i} - y_{\\text{pred}, i} \\right)^2$\n",
    "- Total Sum of Squares (TSS):  $\\sum_{i=1}^{n} \\left( y_{\\text{true}, i} - \\bar{y}_{\\text{true}} \\right)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e049b94-b57f-4401-b6d8-138ebcb03489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_pred):\n",
    "    \"\"\"Compute custom r squared.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true\n",
    "        y_true.\n",
    "    y_pred\n",
    "        y_pred.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r2\n",
    "    \"\"\"\n",
    "    print('y_pred is:',y_pred)\n",
    "    \n",
    "    y_pred, _ = tf.split(y_pred, num_or_size_splits=2, axis=2)\n",
    "    # print('after processed y_pred is: \\n',y_pred)\n",
    "    # print('what is splited _: \\n',_)\n",
    "    \n",
    "    residual = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    # print('residual is? \\n',residual)\n",
    "    \n",
    "    total = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "    # print('what is total: \\n',total)\n",
    "    r2 = tf.subtract(1.0, tf.math.divide(residual, total))\n",
    "    print(r2)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590376f6-2426-4cfd-8581-cd24ed78c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_value = r_squared(y_true_tf, y_pred_tf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
